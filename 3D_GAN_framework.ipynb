{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D-GAN-framework.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data and import libraries"
      ],
      "metadata": {
        "id": "TzsPpSKFksZN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww_DfutOkMWG"
      },
      "outputs": [],
      "source": [
        "#Mount Google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import scipy.ndimage as nd\n",
        "import scipy.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.measure as sk\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import os\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "0Tb5DJH6kyFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#go to root folder of project\n",
        "cd drive/My Drive/3D-GAN"
      ],
      "metadata": {
        "id": "gGYnB2O_k4_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip training data\n",
        "if not os.path.exists('train'):\n",
        "  !unzip train.zip"
      ],
      "metadata": {
        "id": "fo-0KOark8Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = os.getcwd()\n",
        "data_dir = os.path.join(root_dir, 'train')"
      ],
      "metadata": {
        "id": "j9UXk9WylFCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getVoxelFromMat(path, cube_len=64):\n",
        "    voxels = io.loadmat(path)['instance']\n",
        "    voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
        "    if cube_len != 32 and cube_len == 64:\n",
        "        voxels = nd.zoom(voxels, (2, 2, 2), mode='constant', order=0)\n",
        "    return voxels\n",
        "\n",
        "def plotFromVoxels(voxels):\n",
        "    z, x, y = voxels.nonzero()\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(x, y, -z, zdir='z', c='red')\n",
        "    plt.show()\n",
        "\n",
        "class ShapeNetDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, root, cube_len = 32):\n",
        "        \"\"\"Set the path for Data.\n",
        "        Args:\n",
        "            root: image directory.\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.listdir = os.listdir(self.root)\n",
        "        self.cube_len = cube_len\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with open(os.path.join(self.root, self.listdir[index]), \"rb\") as f:\n",
        "            volume = np.asarray(getVoxelFromMat(f, self.cube_len), dtype=np.float32)\n",
        "        return torch.FloatTensor(volume)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.listdir)\n",
        "\n",
        "dataset = ShapeNetDataset(data_dir)\n",
        "\n",
        "sample = dataset.__getitem__(0)\n",
        "plotFromVoxels(sample.numpy())\n",
        "\n",
        "print('voxel shape = {}'.format(sample.shape))\n"
      ],
      "metadata": {
        "id": "Yh_W_llPlFlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Generator and Discriminator models"
      ],
      "metadata": {
        "id": "_w6zdVFLlaHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, channel_sizes = [512, 256, 128, 64], z_shape = 200):\n",
        "    super(Generator, self).__init__()\n",
        "    #first layer\n",
        "\n",
        "    #second layer\n",
        "   \n",
        "    \n",
        "    #third layer\n",
        "   \n",
        "    \n",
        "    #fourth layer\n",
        "   \n",
        "    \n",
        "    #final layer: conv transpose + sigmoid\n",
        "   \n",
        "    \n",
        "  def forward(self, x):\n",
        "    #apply layer 1\n",
        "\n",
        "    #apply layer 2\n",
        "\n",
        "    #apply layer 3\n",
        "\n",
        "    #apply layer 4\n",
        "\n",
        "    #apply layer 5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "z = torch.randn((4, 200, 1, 1, 1))\n",
        "net = Generator()\n",
        "output = net(z)\n",
        "\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "Yb-86_4ylXys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, channel_sizes = [32, 64, 128, 256]):\n",
        "     super(Discriminator, self).__init__()\n",
        "     #layer 1\n",
        "   \n",
        "     #layer 2\n",
        "     \n",
        "  \n",
        "     #layer 4\n",
        "\n",
        "     #layer 5 conv + sigmoid\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #apply layer 1\n",
        "\n",
        "    #apply layer 2\n",
        "\n",
        "    #apply layer 3\n",
        "\n",
        "    #apply layer 4\n",
        "\n",
        "    #apply layer 5\n",
        "\n",
        "\n",
        "dnet = Discriminator()\n",
        "output = dnet(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "IEk3Qy2qmxjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "g_lr = 0.0025\n",
        "d_lr = 0.001\n",
        "nepochs = 1000\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "oJNpfXcNnTMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ShapeNetDataset(root = data_dir)\n",
        "dataloader = DataLoader(dataset, batch_size= batch_size, shuffle = True, drop_last = True, num_workers = 2)\n",
        "\n",
        "gen = Generator().to(device)\n",
        "disc = Discriminator().to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(gen.parameters(), lr = g_lr)\n",
        "d_optimizer = optim.Adam(disc.parameters(), d_lr)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "0Fy4a1N_nUyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for e in range(nepochs):\n",
        "  for i, data in enumerate(tqdm(dataloader, leave=False, desc='Batches'), 0):\n",
        "  #TODO\n",
        "  # move data to device\n",
        "\n",
        "  #TODO\n",
        "  # generate random codes\n",
        "  random_codes = ...\n",
        "  #TODO\n",
        "  # generate samples from random codes\n",
        "\n",
        "  fake_data = ...\n",
        "\n",
        "  #labels\n",
        "  real_labels = torch.zeros(batch_size).to(device)\n",
        "  fake_labels = torch.zeros(batch_size).to(device)\n",
        "\n",
        "  #TODO\n",
        "  # compute discriminator outputs\n",
        "  real_preds = ...\n",
        "  fake_preds = ...\n",
        "  #train discriminator\n",
        "  d_real_acu = torch.le(real_preds.squeeze(), 0.5).float()\n",
        "  d_fake_acu = torch.ge(fake_preds.squeeze(), 0.5).float()\n",
        "  d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
        "\n",
        "  if d_total_acu < 0.8:\n",
        "    #TODO \n",
        "    #compute discriminator loss, back propagate and optimize discriminator\n",
        "\n",
        "  #generate fake shapes\n",
        "  fake_data = gen(random_codes)\n",
        "  fake_preds = disc(fake_data).view(-1,)\n",
        "\n",
        "  #compute generator loss, back propagate and optimize generator\n"
      ],
      "metadata": {
        "id": "6am5BHSynVae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}